{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mzy4PWwvBN1P"
   },
   "source": [
    "<img src=\"img/logo.png\" width=\"50%\">\n",
    "\n",
    "# AutoML Vision per la classificazione di radiografie mediche\n",
    "\n",
    "---\n",
    "\n",
    " A cura di: Andrea Crotti e Marco Feroldi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CW_H-3rBnqY"
   },
   "source": [
    "# **Rilevazione della polmonite**\n",
    "\n",
    "\n",
    "Google Cloud AutoML Vision semplifica la creazione di modelli personalizzati di visione da utilizzare per il riconoscimento di immagini.\n",
    "\n",
    "Vengono sfruttate architetture di reti neurali per la ricerca al fine di trovare la migliore rete e la configurazione ottimale dei parametri, così da minimizzare la perdita del modello.\n",
    "Successivamente verrà mostrato come utilizzare Google Cloud AutoML Vision per sviluppare una classificazione di immagini di radiografie mediche del torace, al fine di riuscire a diagnosticare quanto più precisamente possibile la presenza della **polmonite**.\n",
    "\n",
    "**Polmonite**\n",
    "\n",
    "<img src=\"img/pneumonia.jpg\" width=\"100%\">\n",
    "\n",
    "Una normale radiografia (nel pannello di sinistra) del torace mostra polmoni chiari senza aree anomale opache visibili nell’immagine.\n",
    "\n",
    "La polmonite **batterica**, visibile al centro, presenta invece un consolida- mento lobare focale, in questo caso nel lobo superiore destro, indicato dalle frecce.\n",
    "Infine la polmonite **virale** (nel pannello di destra) si manifesta con un pat- tern più \"interstiziale\" più diffuso in entrambi i polmoni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ihOMHSVhFF5s"
   },
   "source": [
    "\n",
    "# **Dataset**\n",
    "Il dataset contiene:\n",
    "\n",
    "*   5,232 immagini di radiografie al torace di bambini.\n",
    "*   3,883 di queste immagini sono esempi di polmonite batterica (2,538) e virale (1,345).\n",
    "* 1,349 esempi rappresentano immagini di radiografie di bambini sani. \n",
    "\n",
    "Il dataset è presente su Kaggle e accessibile gratuitamente dal seguente link:\n",
    "\n",
    "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1K6esolKdxH"
   },
   "source": [
    "# 1. Creare il progetto\n",
    "\n",
    "Per farlo è necessario andare nella console di Google Cloud, dal seguente link: \n",
    "\n",
    "https://cloud.google.com/\n",
    "\n",
    "<img src=\"img/console.png\" width=\"100%\">\n",
    "\n",
    "Dopo aver aperto la console, è necessario aprire Cloud ML Vision cliccando prima sulle 3 linee in alto a sinistra nella dashboard. \n",
    "\n",
    "Successivamente si seleziona Vision, nella sezione **Intelligenza Artificiale**.\n",
    "\n",
    "<img src=\"img/vision.png\" width=\"100%\">\n",
    "\n",
    "Selezionare **Classificazione delle immagini**.\n",
    "\n",
    "La prima cosa da fare è quella di creare il progetto da utilizzare. \n",
    "Per farlo è necessario cliccare in alto a sinistra sul progetto attualmente selezionato (potrebbe essere quello di default).\n",
    "\n",
    "<img src=\"img/new-project-click.png\" width=\"100%\">\n",
    "\n",
    "Si clicca poi su **Nuovo progetto**.\n",
    "\n",
    "<img src=\"img/new-project.png\" width=\"100%\">\n",
    "\n",
    "Si immette un nome, e si clicca su **Crea**.\n",
    "\n",
    "<img src=\"img/new-project-name.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynjuYIbBGLkr"
   },
   "source": [
    "# 2. Abilitare AutoML Cloud Vision su GCP\n",
    "\n",
    "Una volta creato il progetto, è necessario fornire le autorizzazioni per l'esecuzione delle API chee AutoML richiede.\n",
    "\n",
    "Bisogna quindi impostare le API necessarie al progetto, i permessi e il bucket su Cloud Storage per immagazzinare le immagini per la modellizzazione e il test.\n",
    "\n",
    "Cliccare su **SET UP NOW** nella schermata mostrata.\n",
    "\n",
    "<img src=\"img/setup.png\" width=\"100%\">\n",
    "\n",
    "Siamo a questo punto in grado di creare un **Dataset** per costruire un modello di classificazione personalizzato su AutoML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANKnwdEtGtT7"
   },
   "source": [
    "# 3. Scaricare il Dataset su Google Cloud Storage\n",
    "\n",
    "Attivare la Cloud shell in alto a destra, per lanciare l’istanza della VM al fine di scaricare il dataset da Kaggle, estrarlo e caricarlo nello storage bucket.\n",
    "\n",
    "Installare la CLI di Kaggle, al fine di poter scaricare i dataset da Kaggle. Eseguire quindi il seguente codice:\n",
    "\n",
    "```\n",
    "pip install kaggle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell di breve durata\n",
    "\n",
    "Risulta importante considerare che l’istanza della Cloud Shell è di breve durata, e non mantiene i cambiamenti effettuati al sistema al termine della sessione: sarà infatti necessario reinstallare pacchetti e riapplicare le configurazioni al riavvio.\n",
    "\n",
    "Inoltre, se il dataset è particolarmente ampio, esistono altre opzioni, come la possibilità di usare una VM a rotazione, di scaricare il dataset, estrarlo e caricarlo successivamente sul Cloud Storage.\n",
    "\n",
    "È inoltre presente la possibilità di progettare altre sequenze di operazioni avanzate per immettere i dati in Google Cloud Platform per l’analisi e il machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dLLogrINHQpY"
   },
   "source": [
    "## **Kaggle API Token**\n",
    "\n",
    "Una volta completata l’installazione della CLI di Kaggle, è necessario sca- ricarne il token che permette alla CLI di autenticarsi su Kaggle e scaricare i dataset desiderati.\n",
    "\n",
    "Per farlo è necessario:\n",
    "* Accedere al proprio account di Kaggle.\n",
    "* Andare nella propria area personale.\n",
    "* Cliccare su **Crea nuovo API Token**.\n",
    "\n",
    "<img src=\"img/kaggle_token.png\" width=\"100%\">\n",
    "\n",
    "Una volta scaricato il file *kaggle.json* è necessario caricarlo sulla Cloud Shell. Per farlo è necessario cliccare sui 3 pallini in alto a destra nella shell e selezionare **Carica file**.\n",
    "\n",
    "<img src=\"img/kaggle_upload.png\" width=\"100%\">\n",
    "\n",
    "Creare la cartella *.kaggle*, normalmente non esistente\n",
    "\n",
    "```\n",
    "mkdir .kaggle\n",
    "```\n",
    "\n",
    "Spostare il file caricato nella directory .kaggle, usando il comando seguente:\n",
    "\n",
    "```\n",
    "mv kaggle.json .kaggle/kaggle.json\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z921LUsNZiy"
   },
   "source": [
    "## Download ed estrazione del Dataset\n",
    "\n",
    "Scaricare il dataset da Kaggle e metterlo su Google Storage.\n",
    "\n",
    "```\n",
    "kaggle datasets download paultimothymooney/chest-xray-pneumonia\n",
    "```\n",
    "\n",
    "Estrarre il dataset, con i due seguenti comandi (uno in sequenza all'altro).\n",
    "\n",
    "```\n",
    "unzip chest-xray-pneumonia.zip\n",
    "unzip chest_xray.zip\n",
    "```\n",
    "\n",
    "Spostare il dataset dall'istanza della Cloud Shell (in quanto di breve durata) e spostarla nel bucket di Cloud Storage creato.\n",
    "\n",
    "```\n",
    "gsutil -m cp -r chest_xray gs://gs://gcp-prova-vcm//chest_xray/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset snello\n",
    "\n",
    "È presente un dataset più snello, scaricabile sempre da Kaggle con il seguente comando.\n",
    "\n",
    "```\n",
    "kaggle datasets download marcoferoldi/chest-xray-small\n",
    "```\n",
    "\n",
    "Estrarre il dataset, con i due seguenti comandi (uno in sequenza all'altro).\n",
    "\n",
    "```\n",
    "unzip chest-xray-small.zip\n",
    "```\n",
    "\n",
    "Spostare il dataset dall'istanza della Cloud Shell (in quanto di breve durata) e spostarla nel bucket di Cloud Storage creato.\n",
    "\n",
    "```\n",
    "gsutil -m cp -r chest_xray_small gs://gs://gcp-prova-vcm//chest_xray/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPrcaHi6OOaw"
   },
   "source": [
    "# 3. Preparazione del dataset per la modellizzazione\n",
    "\n",
    "Avviare il Jupyter Notebook su Google Cloud AI Platform.\n",
    "Andare quindi nella dashboard di GCP, e nella sezione **Intelligenza Artificiale** selezionare **AI Platform** e poi **Notebooks**.\n",
    "\n",
    "<img src=\"img/notebook.png\" width=\"100%\">\n",
    "\n",
    "Creare una nuova istanza di un Notebook, selezionando **Tensorflow 2.0**.\n",
    "\n",
    "<img src=\"img/new_istance.png\" width=\"100%\">\n",
    "\n",
    "Scegliere un nome per l'istanza e crearla, eventualmente personalizzandola a piacere.\n",
    "\n",
    "<img src=\"img/create_instance.png\" width=\"100%\">\n",
    "\n",
    "Cliccare su **CREA** per creare l'istanza.\n",
    "\n",
    "Cliccare quindi su **APRI JUPYTERLAB** relativo all'istanza creata.\n",
    "\n",
    "Prima di costruire un modello di riconoscimento immagini con AutoML Cloud Vision, il dataset va preparato in modo da rispettare alcuni requisiti:\n",
    "\n",
    "1. Per il training, sono supportate immagini nei formati JPEG, PNG, WEBP, GIF, BMP, TIFF e ICO, che non superino la massima dimensione di 30MB per immagine.\n",
    "\n",
    "2. I formati JPEG, PNG e GID sono supportati con una massima dimensione per immagine di 1.5MB.\n",
    "\n",
    "3. È consigliato separare le categorie di immagini creando le sottocartele per categorie, e mettendo le immagini al loro interno.\n",
    "\n",
    "4. Infine, creare un file CSV che fa riferimento al percorso delle immagini e alle rispettive classi. AutoML utilizza il file CSV per riferirsi elle locazioni delle immagini (e le relative classi) per la fase di training. Il file CSV va posto nello stesso Google Cloud Storage bucket contenente i file delle immagini. Utilizzare il bucked automaticamente creato nella configurazione di AutoML vision. In questo caso, il bucket automaticamente creato si chiama ***gs://ekabasandbox-vcm.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVknUcguyLG7"
   },
   "source": [
    "\n",
    "## 3.1 Script di Pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5oGuAxJyMxn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4037,
     "status": "error",
     "timestamp": 1559069802850,
     "user": {
      "displayName": "Marco Feroldi",
      "photoUrl": "",
      "userId": "12260744672863130399"
     },
     "user_tz": -120
    },
    "id": "VNpDWPj_zBfn",
    "outputId": "aac6cb36-81fd-439d-c0ea-05c51cd6346e"
   },
   "outputs": [],
   "source": [
    "# Instanziare un client\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_-zKPEDzC-g"
   },
   "outputs": [],
   "source": [
    "# Inserire il nome del proprio bucket\n",
    "bucket_name = 'gcp-prova-vcm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fbuD5YEzFHf"
   },
   "outputs": [],
   "source": [
    "# Prelievo del bucket dal Google Cloud Storage\n",
    "bucket = storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfCqtOIozGe0"
   },
   "outputs": [],
   "source": [
    "# Estrarre i blob nel train dataset\n",
    "blobs = bucket.list_blobs(prefix='chest_xray/chest_xray/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUtOcEIszHcG"
   },
   "outputs": [],
   "source": [
    "# Prendere la lista dei blob\n",
    "blob_list = []\n",
    "for blob in blobs:\n",
    "    blob_list.append(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6h6Zq-8zIsk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5219"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero di elementi del dataset\n",
    "\n",
    "len(blob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHtah-QczKMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chest_xray/chest_xray/train/.DS_Store\n",
      "chest_xray/chest_xray/train/NORMAL/.DS_Store\n"
     ]
    }
   ],
   "source": [
    "print(blob_list[0])\n",
    "print(blob_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6uBjHFZzL9I"
   },
   "outputs": [],
   "source": [
    "# Rimuovere i file .DS_Store dalla lista creata dal sistema\n",
    "\n",
    "i, length = 0, len(blob_list)\n",
    "bucket_prefix = 'gs://gcp-prova-vcm/'\n",
    "data = []\n",
    "for blob in blob_list:\n",
    "    if '.DS_Store' not in blob:\n",
    "        entry = [''.join([bucket_prefix, blob]), blob.split('/')[3]]\n",
    "        data.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-EOT4GAzNFE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://gcp-prova-vcm/chest_xray/chest_xray/train/NORMAL/IM-0115-0001.jpeg', 'NORMAL']\n",
      "['gs://gcp-prova-vcm/chest_xray/chest_xray/train/NORMAL/IM-0117-0001.jpeg', 'NORMAL']\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MpQ7Zw3zOE4"
   },
   "outputs": [],
   "source": [
    "# Convertire in un Pandas DataFrame\n",
    "data_pd = pd.DataFrame(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pj4DTF2ZzO_S"
   },
   "outputs": [],
   "source": [
    "# Creazione del file CSV\n",
    "data_pd.to_csv(\"data.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NEDkU6qzPzc"
   },
   "outputs": [],
   "source": [
    "# Upload data.csv sul Google Cloud Storage\n",
    "output_blob = bucket.blob('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gf1GnanIzQzq"
   },
   "outputs": [],
   "source": [
    "output_blob.upload_from_filename('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creazione del modello con AutoML Vision\n",
    "\n",
    "In AutoML Vision cliccare su **Nuovo Dataset**\n",
    "\n",
    "*** IMG ***\n",
    "\n",
    "Scegliere un nome per il progetto e selezionare il file CSV creato precedentemente e posto nel Cloud Storage bucket creato da AutoML.\n",
    "\n",
    "Ignorare eventuali messaggi di file duplicati allocati.\n",
    "\n",
    "Effettuare il **Training** del modello.\n",
    "\n",
    "*** IMG ***\n",
    "\n",
    "Dopo aver completato il training, cliccare su **Valutazione** per scoprire le performance del modello creato. \n",
    "\n",
    "*** IMG ***\n",
    "\n",
    "Sono visibili:\n",
    "* Precision\n",
    "* Recall\n",
    "* Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test del modello\n",
    "\n",
    "Cliccare su **Previsione**\n",
    "\n",
    "A questo punto è possibile caricare un'immagine e far sì che il modello effettui la sua previsione, comunicando anche le relative percentuali di affidabilità per ciascuna classe di valutazione."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoML Vision.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
